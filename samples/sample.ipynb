{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect(database=':memory:', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * exclude(month, year, site) FROM parquet_scan('../../../dados_lumet/site=CS130/**/*.parquet', hive_partitioning = true) WHERE year=2023 AND month=12 AND TIMESTAMP>'2023-12-01 12:00:00' AND TIMESTAMP<='2023-12-01 13:00:00' order by TIMESTAMP;\"\n",
    "result = con.execute(query)\n",
    "\n",
    "df_hf = result.pl().sort(\"TIMESTAMP\").upsample(time_column=\"TIMESTAMP\", every=\"100ms\", maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = df_hf.with_columns((df_hf[\"TS\"] + 273.15).alias(\"TS\"))\n",
    "df_hf = df_hf.with_columns((df_hf[\"Temp_LI7500A\"] + 273.15).alias(\"Temp_LI7500A\"))\n",
    "df_hf = df_hf.with_columns((df_hf[\"Pressao_LI7500A\"] * 1000).alias(\"Pressao_LI7500A\"))\n",
    "df_hf = df_hf.with_columns((df_hf[\"Temp_LI7700\"] + 273.15).alias(\"Temp_LI7700\"))\n",
    "df_hf = df_hf.with_columns((df_hf[\"Pressao_LI7700\"] * 1000).alias(\"Pressao_LI7700\"))\n",
    "\n",
    "df_hf = df_hf.rename(lambda column_name: column_name.replace(\"_\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * exclude(year, site) FROM parquet_scan('../../../dados_lumet/site=CS131/**/*.parquet', hive_partitioning = true) WHERE TIMESTAMP>'2023-12-01 12:00:00' AND TIMESTAMP<='2023-12-01 13:00:00' order by TIMESTAMP;\"\n",
    "result = con.execute(query)\n",
    "\n",
    "df_lf = result.pl().sort(\"TIMESTAMP\").upsample(time_column=\"TIMESTAMP\", every=\"1s\", maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeddy.config_def import Anemometer3DConfig, GasAnalyzer\n",
    "\n",
    "anemometer3d = Anemometer3DConfig(\n",
    "    manufacturer=\"csi\",\n",
    "    model=\"csat3_1\",\n",
    "    sw_version=\"ddd\",\n",
    "    id=\"ddd\",\n",
    "    height=3.0,\n",
    "    wformat=\"uvw\",\n",
    "    wref=\"na\",\n",
    "    north_offset=90.0,\n",
    "    northward_separation=0.0,\n",
    "    eastward_separation=0.0,\n",
    "    vertical_separation=0.0,\n",
    "    vpath_length=0.115,\n",
    "    hpath_length=0.058,\n",
    "    tau=0.1 # 1/60\n",
    ")\n",
    "\n",
    "co2_analyzer = GasAnalyzer(\n",
    "    manufacturer=\"licor\",\n",
    "    model=\"li7500a_1\",\n",
    "    sw_version=\"ddd\",\n",
    "    id=\"ddd\",\n",
    "    tube_length=0.0,\n",
    "    tube_diameter=0.0,\n",
    "    tube_flowrate=0.0,\n",
    "    northward_separation=20.0,\n",
    "    eastward_separation=-10.0,\n",
    "    vertical_separation=0.0,\n",
    "    vpath_length=1.0,\n",
    "    hpath_length=1.0,\n",
    "    tau=0.1,\n",
    "    kw=0.15,\n",
    "    ko=0.0085\n",
    ")\n",
    "\n",
    "ch4_analyzer = GasAnalyzer(\n",
    "    manufacturer=\"licor\",\n",
    "    model=\"li7700_2\",\n",
    "    sw_version=\"1.0.29\",\n",
    "    id=\"ddd\",\n",
    "    tube_length=0.0,\n",
    "    tube_diameter=0.0,\n",
    "    tube_flowrate=0.0,\n",
    "    northward_separation=-20.0,\n",
    "    eastward_separation=-10.0,\n",
    "    vertical_separation=0.0,\n",
    "    vpath_length=1.0,\n",
    "    hpath_length=1.0,\n",
    "    tau=0.1,\n",
    "    kw=0.15,\n",
    "    ko=0.0085\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative cov\n",
    "\n",
    "# # Merge the dataframes on the TIMESTAMP column\n",
    "# mean_df_ext = (\n",
    "#     df_hf.get_column(\"TIMESTAMP\")\n",
    "#     .to_frame()\n",
    "#     .join(mean_df, on=\"TIMESTAMP\", how=\"left\")\n",
    "#     .fill_null(strategy=\"forward\")\n",
    "# )\n",
    "\n",
    "# # In eddypro defined as Prime\n",
    "# fluctuations = (\n",
    "#     df_hf.get_column(\"TIMESTAMP\")\n",
    "#     .to_frame()\n",
    "#     .with_columns(df_hf.select(cov_cols[1:]) - mean_df_ext.select(cov_cols[1:]))\n",
    "# )\n",
    "\n",
    "# cov_agg = [\n",
    "#     (pl.col(v[0]) * pl.col(v[1])).mean().alias(f\"cov_{v[0]}_{v[1]}\")\n",
    "#     for v in cov_combination\n",
    "# ]\n",
    "\n",
    "# # Calculate covariance of fluctuations over the original interval\n",
    "# covariances = fluctuations.group_by_dynamic(\n",
    "#     index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\"\n",
    "# ).agg(cov_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance BasicStats from fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "resample_interval = \"30m\"\n",
    "\n",
    "cov_cols = [\"TIMESTAMP\", \"u\", \"v\", \"w\", \"TS\", \"CO2\", \"H2O\", \"CH4\"]\n",
    "\n",
    "mean_df = (\n",
    "    df_hf.select(cov_cols)\n",
    "    .group_by_dynamic(\n",
    "        \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    "    )\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").mean())\n",
    ")\n",
    "\n",
    "cov_combination = list(product(cov_cols[1:], cov_cols[1:]))\n",
    "\n",
    "# Merge the dataframes on the TIMESTAMP column\n",
    "mean_df_ext = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .join(mean_df, on=\"TIMESTAMP\", how=\"left\")\n",
    "    .fill_null(strategy=\"forward\")\n",
    ")\n",
    "\n",
    "\n",
    "mean_var_df = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .with_columns(\n",
    "        (df_hf.select(cov_cols[1:])\n",
    "        - mean_df_ext.select(cov_cols[1:]))\n",
    "    ).group_by_dynamic(\n",
    "        \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    "    )\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").sum()/(pl.all().exclude(\"TIMESTAMP\").count() - pl.all().exclude(\"TIMESTAMP\").null_count()))\n",
    ")\n",
    "\n",
    "mean_df = mean_var_df.select(cov_cols[1:]) + mean_df.select(cov_cols[1:])\n",
    "\n",
    "\n",
    "\n",
    "# In eddypro defined as Prime\n",
    "fluctuations = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .with_columns(df_hf.select(cov_cols[1:]) - mean_df_ext.select(cov_cols[1:]))\n",
    ")\n",
    "\n",
    "cov_agg = [\n",
    "    (pl.col(v[0]) * pl.col(v[1])).mean().alias(f\"cov_{v[0]}_{v[1]}\")\n",
    "    for v in cov_combination\n",
    "]\n",
    "\n",
    "# Calculate covariance of fluctuations over the original interval\n",
    "covariances = fluctuations.group_by_dynamic(\n",
    "    index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\"\n",
    ").agg(cov_agg)\n",
    "\n",
    "# # Faster but less precise\n",
    "# cov_agg = [pl.cov(v[0], v[1]).alias(f\"cov_{v[0]}_{v[1]}\") for v in cov_combination]\n",
    "# covariances = df_hf.select(cov_cols).group_by_dynamic(\"TIMESTAMP\", every=resample_interval, closed=\"right\").agg(cov_agg)\n",
    "\n",
    "skewness = (\n",
    "    df_hf.select(cov_cols)\n",
    "    .group_by_dynamic(index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\")\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").skew())\n",
    ")\n",
    "\n",
    "kurtosis = (\n",
    "    df_hf.select(cov_cols)\n",
    "    .group_by_dynamic(index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\")\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").kurtosis(fisher=False))\n",
    ")\n",
    "\n",
    "\n",
    "# TKE (e.g. Stull, 1988)\n",
    "TKE = df_hf.select([\"TIMESTAMP\", \"u\", \"v\", \"w\"]).group_by_dynamic(\n",
    "    index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\"\n",
    ").agg(\n",
    "    pl.all().exclude(\"TIMESTAMP\").pow(2).sum()\n",
    "    / pl.all().exclude(\"TIMESTAMP\").is_not_null().sum()\n",
    ").with_columns(\n",
    "    ((pl.col(\"u\") + pl.col(\"v\") + pl.col(\"w\"))*0.5).alias(\"TKE\")\n",
    ").select([\"TIMESTAMP\", \"TKE\"])\n",
    "\n",
    "\n",
    "offset = anemometer3d.north_offset - 180.0\n",
    "wind_dir = (\n",
    "    df_hf.select([\"TIMESTAMP\", \"u\", \"v\"])\n",
    "    .with_columns(\n",
    "        (180 - pl.arctan2d(pl.col(\"v\"), pl.col(\"u\")) + offset)\n",
    "        .mod(360)\n",
    "        .alias(\"wind_dir\")\n",
    "    )\n",
    "    .select([\"TIMESTAMP\", \"wind_dir\"])\n",
    ")\n",
    "\n",
    "\n",
    "wind_dir_mean = wind_dir.group_by_dynamic(\n",
    "    \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    ").agg(\n",
    "    pl.arctan2d(\n",
    "        pl.col(\"wind_dir\").radians().sin().mean().degrees(),\n",
    "        pl.col(\"wind_dir\").radians().cos().mean().degrees(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Approximate standard deviation of wind direction (see Yamartino, 1984:\n",
    "# https://journals.ametsoc.org/doi/pdf/10.1175/1520-0450%281984%29023%3C1362%3AACOSPE%3E2.0.CO%3B2)\n",
    "\n",
    "wind_dir_std_dev = wind_dir.group_by_dynamic(\n",
    "    \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    ").agg(\n",
    "    (\n",
    "        1\n",
    "        - (\n",
    "            pl.col(\"wind_dir\").radians().sin().mean().pow(2)\n",
    "            + pl.col(\"wind_dir\").radians().cos().mean().pow(2)\n",
    "        )\n",
    "    )\n",
    "    .sqrt()\n",
    "    .alias(\"eps\")\n",
    ").with_columns(\n",
    "    (pl.col(\"eps\").arcsin()\n",
    "    * (1 + (2 / np.sqrt(3) - 1) * pl.col(\"eps\").pow(3))).degrees().alias(\"std_dev\")\n",
    ").select([\"TIMESTAMP\", \"std_dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>u</th><th>v</th><th>w</th><th>TS</th><th>CO2</th><th>H2O</th><th>CH4</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.063175</td><td>1.993309</td><td>0.062974</td><td>306.377361</td><td>16.28678</td><td>1201.593074</td><td>0.06722</td></tr><tr><td>1.437255</td><td>1.723983</td><td>0.065025</td><td>307.205385</td><td>16.268556</td><td>1210.264405</td><td>0.066968</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌──────────┬──────────┬──────────┬────────────┬───────────┬─────────────┬──────────┐\n",
       "│ u        ┆ v        ┆ w        ┆ TS         ┆ CO2       ┆ H2O         ┆ CH4      │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---        ┆ ---       ┆ ---         ┆ ---      │\n",
       "│ f64      ┆ f64      ┆ f64      ┆ f64        ┆ f64       ┆ f64         ┆ f64      │\n",
       "╞══════════╪══════════╪══════════╪════════════╪═══════════╪═════════════╪══════════╡\n",
       "│ 1.063175 ┆ 1.993309 ┆ 0.062974 ┆ 306.377361 ┆ 16.28678  ┆ 1201.593074 ┆ 0.06722  │\n",
       "│ 1.437255 ┆ 1.723983 ┆ 0.065025 ┆ 307.205385 ┆ 16.268556 ┆ 1210.264405 ┆ 0.066968 │\n",
       "└──────────┴──────────┴──────────┴────────────┴───────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_cols = [\n",
    "    \"TIMESTAMP\",\n",
    "    \"Temp-LI7500A\",\n",
    "    \"Pressao-LI7500A\",\n",
    "    \"CH4-mole-fraction\",\n",
    "    \"Temp-LI7700\",\n",
    "    \"Pressao-LI7700\",\n",
    "]\n",
    "\n",
    "user_data = df_hf.select(user_data_cols)\n",
    "\n",
    "cov_combination = list(product(user_data_cols[1:], user_data_cols[1:]))\n",
    "\n",
    "\n",
    "# Compute the mean\n",
    "user_mean_df = (\n",
    "    df_hf.select(user_data_cols)\n",
    "    .group_by_dynamic(\n",
    "        \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    "    )\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").mean())\n",
    ")\n",
    "\n",
    "cov_combination = list(product(user_data_cols[1:], user_data_cols[1:]))\n",
    "\n",
    "# Merge the dataframes on the TIMESTAMP column\n",
    "mean_df_ext = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .join(user_mean_df, on=\"TIMESTAMP\", how=\"left\")\n",
    "    .fill_null(strategy=\"forward\")\n",
    ")\n",
    "\n",
    "mean_var_df = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .with_columns(\n",
    "        (df_hf.select(user_data_cols[1:])\n",
    "        - mean_df_ext.select(user_data_cols[1:]))\n",
    "    ).group_by_dynamic(\n",
    "        \"TIMESTAMP\", every=resample_interval, closed=\"right\", label=\"datapoint\"\n",
    "    )\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").sum()/(pl.all().exclude(\"TIMESTAMP\").count() - pl.all().exclude(\"TIMESTAMP\").null_count()))\n",
    ")\n",
    "\n",
    "user_mean_df = mean_var_df.select(user_data_cols[1:]) + user_mean_df.select(user_data_cols[1:])\n",
    "\n",
    "# In eddypro defined as Prime\n",
    "user_fluctuations = (\n",
    "    df_hf.get_column(\"TIMESTAMP\")\n",
    "    .to_frame()\n",
    "    .with_columns(\n",
    "        df_hf.select(user_data_cols[1:]) - mean_df_ext.select(user_data_cols[1:])\n",
    "    )\n",
    ")\n",
    "\n",
    "cov_agg = [\n",
    "    (pl.col(v[0]) * pl.col(v[1])).mean().alias(f\"cov_{v[0]}_{v[1]}\")\n",
    "    for v in cov_combination\n",
    "]\n",
    "\n",
    "# Calculate covariance of fluctuations over the original interval\n",
    "user_covariances = user_fluctuations.group_by_dynamic(\n",
    "    index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\"\n",
    ").agg(cov_agg)\n",
    "\n",
    "\n",
    "std_cols = [f\"cov_{c}_{c}\" for c in user_data_cols[1:]]\n",
    "std_agg = [pl.col(v).sqrt().alias(v.split(\"_\")[-1]) for v in std_cols]\n",
    "\n",
    "user_std_dev = user_covariances.with_columns(std_agg).select(user_data_cols)\n",
    "\n",
    "user_skewness = (\n",
    "    df_hf.select(user_data_cols)\n",
    "    .group_by_dynamic(index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\")\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").skew())\n",
    ")\n",
    "\n",
    "user_kurtosis = (\n",
    "    df_hf.select(user_data_cols)\n",
    "    .group_by_dynamic(index_column=\"TIMESTAMP\", every=resample_interval, closed=\"right\")\n",
    "    .agg(pl.all().exclude(\"TIMESTAMP\").kurtosis(fisher=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>u</th><th>v</th><th>w</th><th>TS</th><th>CO2</th><th>H2O</th><th>CH4</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.063175</td><td>1.993309</td><td>0.062974</td><td>306.377361</td><td>16.28678</td><td>1201.593074</td><td>0.06722</td></tr><tr><td>1.437255</td><td>1.723983</td><td>0.065025</td><td>307.205385</td><td>16.268556</td><td>1210.264405</td><td>0.066968</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌──────────┬──────────┬──────────┬────────────┬───────────┬─────────────┬──────────┐\n",
       "│ u        ┆ v        ┆ w        ┆ TS         ┆ CO2       ┆ H2O         ┆ CH4      │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---        ┆ ---       ┆ ---         ┆ ---      │\n",
       "│ f64      ┆ f64      ┆ f64      ┆ f64        ┆ f64       ┆ f64         ┆ f64      │\n",
       "╞══════════╪══════════╪══════════╪════════════╪═══════════╪═════════════╪══════════╡\n",
       "│ 1.063175 ┆ 1.993309 ┆ 0.062974 ┆ 306.377361 ┆ 16.28678  ┆ 1201.593074 ┆ 0.06722  │\n",
       "│ 1.437255 ┆ 1.723983 ┆ 0.065025 ┆ 307.205385 ┆ 16.268556 ┆ 1210.264405 ┆ 0.066968 │\n",
       "└──────────┴──────────┴──────────┴────────────┴───────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace temperature with user_mean\n",
    "\n",
    "mean_df.filter((pl.col(\"TS\") < 220) | (pl.col(\"TS\") > 340))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatisticalScreening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (36_000, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>TIMESTAMP</th><th>u</th><th>v</th><th>w</th><th>TS</th><th>CO2</th><th>H2O</th><th>CH4</th></tr><tr><td>datetime[μs]</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>2023-12-01 12:00:00.100</td><td>0.61125</td><td>1.57325</td><td>0.40625</td><td>306.981934</td><td>16.338131</td><td>1206.360962</td><td>0.06759</td></tr><tr><td>2023-12-01 12:00:00.200</td><td>0.989</td><td>1.75575</td><td>0.202</td><td>306.326752</td><td>16.341631</td><td>1206.800049</td><td>0.06743</td></tr><tr><td>2023-12-01 12:00:00.300</td><td>1.0555</td><td>1.89975</td><td>-0.094</td><td>305.958435</td><td>16.35182</td><td>1206.004028</td><td>0.067372</td></tr><tr><td>2023-12-01 12:00:00.400</td><td>0.83975</td><td>2.026</td><td>0.0265</td><td>305.965393</td><td>16.325371</td><td>1208.625977</td><td>0.067487</td></tr><tr><td>2023-12-01 12:00:00.500</td><td>1.11725</td><td>1.8765</td><td>-0.1125</td><td>306.056152</td><td>16.31052</td><td>1205.051025</td><td>0.067512</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2023-12-01 12:59:59.600</td><td>1.50225</td><td>1.74275</td><td>0.7265</td><td>309.244537</td><td>16.13073</td><td>1264.366943</td><td>0.065951</td></tr><tr><td>2023-12-01 12:59:59.700</td><td>1.281</td><td>2.134</td><td>0.2055</td><td>309.226959</td><td>16.182671</td><td>1249.436035</td><td>0.066012</td></tr><tr><td>2023-12-01 12:59:59.800</td><td>1.65275</td><td>2.249</td><td>0.581</td><td>309.083099</td><td>16.16498</td><td>1255.180054</td><td>0.065895</td></tr><tr><td>2023-12-01 12:59:59.900</td><td>1.21425</td><td>2.186</td><td>0.58625</td><td>309.333984</td><td>16.16173</td><td>1257.842041</td><td>0.066062</td></tr><tr><td>2023-12-01 13:00:00</td><td>1.09625</td><td>1.79125</td><td>0.76575</td><td>309.016479</td><td>16.18788</td><td>1246.280029</td><td>0.066042</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (36_000, 8)\n",
       "┌──────────────┬─────────┬─────────┬─────────┬────────────┬───────────┬─────────────┬──────────┐\n",
       "│ TIMESTAMP    ┆ u       ┆ v       ┆ w       ┆ TS         ┆ CO2       ┆ H2O         ┆ CH4      │\n",
       "│ ---          ┆ ---     ┆ ---     ┆ ---     ┆ ---        ┆ ---       ┆ ---         ┆ ---      │\n",
       "│ datetime[μs] ┆ f32     ┆ f32     ┆ f32     ┆ f32        ┆ f32       ┆ f32         ┆ f32      │\n",
       "╞══════════════╪═════════╪═════════╪═════════╪════════════╪═══════════╪═════════════╪══════════╡\n",
       "│ 2023-12-01   ┆ 0.61125 ┆ 1.57325 ┆ 0.40625 ┆ 306.981934 ┆ 16.338131 ┆ 1206.360962 ┆ 0.06759  │\n",
       "│ 12:00:00.100 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 0.989   ┆ 1.75575 ┆ 0.202   ┆ 306.326752 ┆ 16.341631 ┆ 1206.800049 ┆ 0.06743  │\n",
       "│ 12:00:00.200 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.0555  ┆ 1.89975 ┆ -0.094  ┆ 305.958435 ┆ 16.35182  ┆ 1206.004028 ┆ 0.067372 │\n",
       "│ 12:00:00.300 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 0.83975 ┆ 2.026   ┆ 0.0265  ┆ 305.965393 ┆ 16.325371 ┆ 1208.625977 ┆ 0.067487 │\n",
       "│ 12:00:00.400 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.11725 ┆ 1.8765  ┆ -0.1125 ┆ 306.056152 ┆ 16.31052  ┆ 1205.051025 ┆ 0.067512 │\n",
       "│ 12:00:00.500 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ …            ┆ …       ┆ …       ┆ …       ┆ …          ┆ …         ┆ …           ┆ …        │\n",
       "│ 2023-12-01   ┆ 1.50225 ┆ 1.74275 ┆ 0.7265  ┆ 309.244537 ┆ 16.13073  ┆ 1264.366943 ┆ 0.065951 │\n",
       "│ 12:59:59.600 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.281   ┆ 2.134   ┆ 0.2055  ┆ 309.226959 ┆ 16.182671 ┆ 1249.436035 ┆ 0.066012 │\n",
       "│ 12:59:59.700 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.65275 ┆ 2.249   ┆ 0.581   ┆ 309.083099 ┆ 16.16498  ┆ 1255.180054 ┆ 0.065895 │\n",
       "│ 12:59:59.800 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.21425 ┆ 2.186   ┆ 0.58625 ┆ 309.333984 ┆ 16.16173  ┆ 1257.842041 ┆ 0.066062 │\n",
       "│ 12:59:59.900 ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "│ 2023-12-01   ┆ 1.09625 ┆ 1.79125 ┆ 0.76575 ┆ 309.016479 ┆ 16.18788  ┆ 1246.280029 ┆ 0.066042 │\n",
       "│ 13:00:00     ┆         ┆         ┆         ┆            ┆           ┆             ┆          │\n",
       "└──────────────┴─────────┴─────────┴─────────┴────────────┴───────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hf.select(cov_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate fluctuations\n",
    "fluctuations = fluctuations.with_columns([\n",
    "    (pl.col(\"w\") - pl.col(\"mean_w\")).alias(\"fluc_w\"),\n",
    "    (pl.col(\"CO2\") - pl.col(\"mean_CO2\")).alias(\"fluc_CO2\"),\n",
    "    (pl.col(\"H2O\") - pl.col(\"mean_H2O\")).alias(\"fluc_H2O\")\n",
    "])\n",
    "\n",
    "# Calculate covariance of fluctuations over the original interval\n",
    "covariances = fluctuations.groupby_dynamic(\n",
    "    index_column=\"datetime\",\n",
    "    every=resample_interval,\n",
    "    period=\"backward\",\n",
    "    offset=\"0ns\",  # Adjust as needed\n",
    "    closed=\"left\"\n",
    ").agg([\n",
    "    (pl.col(\"fluc_w\") * pl.col(\"fluc_CO2\")).mean().alias(\"cov_w_CO2\"),\n",
    "    (pl.col(\"fluc_w\") * pl.col(\"fluc_H2O\")).mean().alias(\"cov_w_H2O\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "interval = \"30m\"\n",
    "\n",
    "average_df = df.group_by_dynamic(\"TIMESTAMP\", every=interval).agg(pl.all().exclude(\"TIMESTAMP\").mean())\n",
    "\n",
    "ts_col = df.get_column(\"TIMESTAMP\")\n",
    "\n",
    "fluctuations = df-average_df.upsample(time_column=\"TIMESTAMP\", every=\"100ms\", maintain_order=True).select(pl.all().forward_fill())\n",
    "fluctuations = fluctuations.replace_column(0, df.get_column(\"TIMESTAMP\"))\n",
    "\n",
    "cov_w_CO2 = (fluctuations['w'] * fluctuations['CO2']).to_frame().with_columns(ts_col).group_by_dynamic(\"TIMESTAMP\", every=interval).agg(pl.all().exclude(\"TIMESTAMP\").mean())\n",
    "cov_w_H2O = (fluctuations['w'] * fluctuations['H2O']).to_frame().with_columns(ts_col).group_by_dynamic(\"TIMESTAMP\", every=interval).agg(pl.all().exclude(\"TIMESTAMP\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Define your resampling interval (e.g., '5m' for 5 minutes)\n",
    "resample_interval = '5m'  # Change '5m' to your desired interval\n",
    "\n",
    "# Group by interval and calculate means\n",
    "resampled_df = df.groupby_dynamic(\n",
    "    index_column=\"datetime\",\n",
    "    every=resample_interval,\n",
    "    period=\"backward\",\n",
    "    offset=\"0ns\",  # Adjust as needed\n",
    "    closed=\"left\"\n",
    ").agg([\n",
    "    pl.col(\"w\").mean().alias(\"mean_w\"),\n",
    "    pl.col(\"CO2\").mean().alias(\"mean_CO2\"),\n",
    "    pl.col(\"H2O\").mean().alias(\"mean_H2O\")\n",
    "])\n",
    "\n",
    "# Calculate fluctuations based on mean\n",
    "# This requires joining back the means to the original data, or you can calculate directly if only means are needed.\n",
    "fluctuations = df.join(\n",
    "    resampled_df,\n",
    "    on=pl.col(\"datetime\").cast(pl.Date).dt.truncate(resample_interval),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate fluctuations\n",
    "fluctuations = fluctuations.with_columns([\n",
    "    (pl.col(\"w\") - pl.col(\"mean_w\")).alias(\"fluc_w\"),\n",
    "    (pl.col(\"CO2\") - pl.col(\"mean_CO2\")).alias(\"fluc_CO2\"),\n",
    "    (pl.col(\"H2O\") - pl.col(\"mean_H2O\")).alias(\"fluc_H2O\")\n",
    "])\n",
    "\n",
    "# Calculate covariance of fluctuations over the original interval\n",
    "covariances = fluctuations.groupby_dynamic(\n",
    "    index_column=\"datetime\",\n",
    "    every=resample_interval,\n",
    "    period=\"backward\",\n",
    "    offset=\"0ns\",  # Adjust as needed\n",
    "    closed=\"left\"\n",
    ").agg([\n",
    "    (pl.col(\"fluc_w\") * pl.col(\"fluc_CO2\")).mean().alias(\"cov_w_CO2\"),\n",
    "    (pl.col(\"fluc_w\") * pl.col(\"fluc_H2O\")).mean().alias(\"cov_w_H2O\")\n",
    "])\n",
    "\n",
    "print(covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeddy.filters import FluxDataFrame\n",
    "\n",
    "df.flux.config(\"CS_130.metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_metadata_block(metadata, block):\n",
    "    block_data = re.search(fr'\\[{block}\\]\\n(.*?)(?=\\n\\n|\\Z)', metadata, re.DOTALL)\n",
    "    if not block_data:\n",
    "        return None\n",
    "    rows = block_data[0].split('\\n')[1:]\n",
    "    output = {}\n",
    "    for r in rows:\n",
    "        field = r.split(\"=\")\n",
    "        if len(field) == 2:\n",
    "            output[field[0]] = field[1]\n",
    "        elif len(field) == 1:\n",
    "            output[field[0]] = None\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid field: {r}\")\n",
    "    return output\n",
    "\n",
    "with open(\"CS_130.metadata\") as f:\n",
    "    metadata = f.read()\n",
    "\n",
    "read_metadata_block(metadata, \"Site\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def potential_radiation(latit):\n",
    "    \"\"\"\n",
    "    Calculate potential radiation based on latitude on a 30-minute basis.\n",
    "    Returns an array of 17,568 radiation values.\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    solar_constant = 1376.0\n",
    "    p = np.pi\n",
    "    num_points = 17568\n",
    "    RP = np.zeros(num_points)  # Output array for potential radiation\n",
    "\n",
    "    # Calculate day of year (DOY), theta, and other parameters\n",
    "    lDOY = np.arange(1, num_points + 1) // 48 + 1\n",
    "    theta = 2 * p * (lDOY - 1) / 365\n",
    "\n",
    "    ET = (0.000075 + 0.001868 * np.cos(theta) - 0.032077 * np.sin(theta) -\n",
    "          0.014615 * np.cos(2 * theta) - 0.040849 * np.sin(2 * theta))\n",
    "\n",
    "    delta = (0.006918 - 0.399912 * np.cos(theta) + 0.070257 * np.sin(theta) -\n",
    "             0.006758 * np.cos(2 * theta) + 0.000907 * np.sin(2 * theta) -\n",
    "             0.002697 * np.cos(3 * theta) + 0.00148 * np.sin(3 * theta))\n",
    "\n",
    "    LAS = 12 - (np.mod(np.arange(1, num_points + 1), 48) / 2 + 0.25)\n",
    "    LAS = np.abs(LAS)\n",
    "\n",
    "    omega = -15 * LAS\n",
    "    lat_rad = latit * p / 180\n",
    "\n",
    "    omega_rad = omega * p / 180\n",
    "    theta_rad = np.arccos(\n",
    "        np.sin(delta) * np.sin(lat_rad) +\n",
    "        np.cos(delta) * np.cos(lat_rad) * np.cos(omega_rad)\n",
    "    )\n",
    "\n",
    "    rpot = (solar_constant * (1.00011 + 0.034221 * np.cos(theta) +\n",
    "                              0.00128 * np.sin(theta) + 0.000719 * np.cos(2 * theta) +\n",
    "                              0.000077 * np.sin(2 * theta)))\n",
    "\n",
    "    RP = rpot * np.cos(theta_rad)\n",
    "    RP = np.maximum(RP, 0)\n",
    "\n",
    "    return RP\n",
    "\n",
    "plt.plot(potential_radiation(-30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def potential_radiation(latit, dt, flux_window=30):\n",
    "    \"\"\"\n",
    "    Calculate potential radiation based on latitude on a 30-minute basis.\n",
    "    Returns an array of 17,568 radiation values.\n",
    "    \"\"\"\n",
    "    # Constants\n",
    "    solar_constant = 1376.0\n",
    "\n",
    "    # Calculate day of year (DOY), theta, and other parameters\n",
    "    # lDOY = np.arange(1, num_points + 1) // 48 + 1\n",
    "    lDOY = dt.timetuple().tm_yday\n",
    "    theta = 2 * np.pi * (lDOY - 1) / 365\n",
    "\n",
    "    delta = (0.006918 - 0.399912 * np.cos(theta) + 0.070257 * np.sin(theta) -\n",
    "             0.006758 * np.cos(2 * theta) + 0.000907 * np.sin(2 * theta) -\n",
    "             0.002697 * np.cos(3 * theta) + 0.00148 * np.sin(3 * theta))\n",
    "\n",
    "    LAS = 12 - dt.timetuple().tm_hour + dt.timetuple().tm_min/60 + flux_window/2/60 \n",
    "\n",
    "    omega = -15 * LAS\n",
    "    lat_rad = np.radians(latit)\n",
    "\n",
    "    omega_rad = np.radians(omega)\n",
    "    theta_rad = np.arccos(\n",
    "        np.sin(delta) * np.sin(lat_rad) +\n",
    "        np.cos(delta) * np.cos(lat_rad) * np.cos(omega_rad)\n",
    "    )\n",
    "\n",
    "    rpot = (solar_constant * (1.00011 + 0.034221 * np.cos(theta) +\n",
    "                              0.00128 * np.sin(theta) + 0.000719 * np.cos(2 * theta) +\n",
    "                              0.000077 * np.sin(2 * theta)))\n",
    "\n",
    "    pot_rad = rpot * np.cos(theta_rad)\n",
    "    pot_rad = np.maximum(pot_rad, 0)\n",
    "\n",
    "    return pot_rad\n",
    "\n",
    "periods = pd.date_range(start='2022-01-01', periods=48, freq='30T')\n",
    "\n",
    "periods.to_series().apply(lambda x: potential_radiation(-30, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
